{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the PySpark module\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "# Create SparkSession object\n",
    "spark = SparkSession.builder.master('local[*]').appName('oneHot').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Is not the best choose for large data sets\n",
    "flights = spark.read.csv('flights.csv',sep=',',header=True,inferSchema=True,nullValue='NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = flights.withColumnRenamed('mile','km')\n",
    "# Create 'label' column indicating whether flight delayed (1) or not (0)\n",
    "flights = flights.withColumn('label', (flights.delay >=15).cast('integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = flights.filter(flights.label.isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Create an assembler object\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['mon', 'dom' , 'dow','km', 'depart', 'duration' ], outputCol='features')\n",
    "\n",
    "# Consolidate predictor columns\n",
    "flights_assembled = assembler.transform(flights)\n",
    "flights = flights_assembled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets in a 80:20 ratio\n",
    "flights_train, flights_test = flights.randomSplit([0.8, 0.2], seed=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DecisionTreeRegressionModel (uid=dtr_7b00cf39f70f) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_d09c235c87a0) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_a44e713fad43) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_994e7c3ecb58) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_739de57a24e5) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_f967dbeeca22) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_2fa1fd670888) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_53e2703a48ec) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_ab993c53d95f) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_48782d3b5837) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_a6a5ef516293) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_322403624dda) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_f1ba7545c2b8) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_c286a16c6053) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_6237ec7b1289) of depth 5 with 61 nodes, DecisionTreeRegressionModel (uid=dtr_d61e3d6f3484) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_4491bd10d908) of depth 5 with 61 nodes, DecisionTreeRegressionModel (uid=dtr_fac902a22df7) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_e12223eb2605) of depth 5 with 63 nodes, DecisionTreeRegressionModel (uid=dtr_bee6c5313751) of depth 5 with 63 nodes]\n",
      "(6,[0,1,2,3,4,5],[0.219881669186862,0.19304399128669567,0.16940910157223502,0.1373547299836103,0.16745010667310545,0.11286040129749153])\n"
     ]
    }
   ],
   "source": [
    "# Import the classes required\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Create model objects and train on training data\n",
    "tree = DecisionTreeClassifier().fit(flights_train)\n",
    "gbt = GBTClassifier().fit(flights_train)\n",
    "\n",
    "# Compare AUC on testing data\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "evaluator.evaluate(tree.transform(flights_test))\n",
    "evaluator.evaluate(gbt.transform(flights_test))\n",
    "\n",
    "# Find the number of trees and the relative importance of features\n",
    "print(gbt.trees)\n",
    "print(gbt.featureImportances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
